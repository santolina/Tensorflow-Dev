{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Style Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santolina/Tensorflow-Dev/blob/master/Image_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFu1jcWGUkxz",
        "colab_type": "text"
      },
      "source": [
        "#Perceptual Losses for Real-Time Style Transfer and Super-Resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmuh9H423w9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf296498-54e0-458a-be4b-55934fa3efdf"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_VnGoBS4B8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whYcXZ824pqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define residual block\n",
        "\n",
        "def residual_block(input_ts):\n",
        "  # functional AP\n",
        "  x = tf.keras.layers.Conv2D(128, (3,3), strides=1, padding='same')(input_ts)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(128, (3,3), strides=1, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  return tf.keras.layers.Add()([x, input_ts])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Xi8js9V5RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define encoder_decoder function\n",
        "\n",
        "def transfer_network(input_shape=(224, 224, 3)):\n",
        "  # encoder\n",
        "  input_ts = tf.keras.layers.Input(shape=input_shape, name='input')\n",
        "\n",
        "  # normalize input value to [0, 1]\n",
        "  x = tf.keras.layers.Lambda(lambda a: a/255.)(input_ts)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(32, (9, 9), strides=1, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(64, (3, 3), strides=2, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  \n",
        "  x = tf.keras.layers.Conv2D(128, (3, 3), strides=2, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  for _ in range(5):\n",
        "    x = residual_block(x)\n",
        "\n",
        "  # decoder\n",
        "  x = tf.keras.layers.Conv2DTranspose(64, (3,3), strides=2, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2DTranspose(32, (3,3), strides=2, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2DTranspose(3, (9,9), strides=1, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('tanh')(x)\n",
        "\n",
        "  # re-normalize output value to [0, 255]\n",
        "  gen_out = tf.keras.layers.Lambda(lambda a: (a+1)*127.5)(x)\n",
        "\n",
        "  model_gen = tf.keras.Model(\n",
        "      inputs = [input_ts],\n",
        "      outputs = [gen_out]\n",
        "  )\n",
        "\n",
        "  return model_gen\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8102InkYbtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape=(224, 224, 3)\n",
        "\n",
        "model_gen = transfer_network(input_shape=input_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abppumxDYh--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af8abe7c-bf8d-4bf2-bdb5-f27e22ca14cc"
      },
      "source": [
        "model_gen.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 224, 224, 3)  0           input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 224, 224, 32) 7808        lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 224, 224, 32) 128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 224, 224, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 112, 112, 64) 18496       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 112, 112, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 56, 56, 128)  73856       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 56, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 56, 56, 128)  147584      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 56, 56, 128)  147584      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 56, 56, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 56, 56, 128)  0           batch_normalization_4[0][0]      \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 56, 56, 128)  147584      add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 56, 56, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 56, 56, 128)  147584      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 56, 56, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 128)  0           batch_normalization_6[0][0]      \n",
            "                                                                 add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 56, 56, 128)  147584      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 56, 56, 128)  512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 56, 56, 128)  147584      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 56, 56, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 128)  0           batch_normalization_8[0][0]      \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 56, 56, 128)  147584      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 56, 56, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 56, 56, 128)  147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 56, 56, 128)  512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 128)  0           batch_normalization_10[0][0]     \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 56, 56, 128)  147584      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 56, 56, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 56, 56, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 56, 56, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 56, 56, 128)  0           batch_normalization_12[0][0]     \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 112, 112, 64) 73792       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 112, 112, 64) 256         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 112, 112, 64) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 224, 224, 32) 18464       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 224, 224, 32) 128         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 224, 224, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 224, 224, 3)  7779        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 224, 224, 3)  12          conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 224, 224, 3)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 224, 224, 3)  0           activation_10[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,682,447\n",
            "Trainable params: 1,679,241\n",
            "Non-trainable params: 3,206\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S2KpPUkYmkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "6a4d6c72-b63c-4015-cee4-373a35139e5b"
      },
      "source": [
        "# define loss_network\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# call VGG16 model\n",
        "vgg16 = VGG16()\n",
        "\n",
        "# freeze weight parameters\n",
        "for layer in vgg16.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# preprocessing\n",
        "def norm_vgg16(x):\n",
        "  \"\"\" RGB->BGR conversion + centorize\"\"\"\n",
        "  return (x[:, :, :, ::-1] - 120) / 255.\n",
        "\n",
        "# define name for each layer to extract features\n",
        "style_layer_names = (\n",
        "    'block1_conv2',\n",
        "    'block2_conv2',\n",
        "    'block3_conv3',\n",
        "    'block4_conv3'\n",
        ")\n",
        "\n",
        "content_layer_names = ('block3_conv3', )\n",
        "\n",
        "\n",
        "# List to store intermidiate outputs\n",
        "style_outputs_gen = []\n",
        "contents_outputs_gen = []\n",
        "\n",
        "input_gen = model_gen.output # input is transfer_network's output\n",
        "\n",
        "z = tf.keras.layers.Lambda(norm_vgg16)(input_gen)\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "  z = layer(z)\n",
        "  if layer.name in style_layer_names:\n",
        "    style_outputs_gen.append(z)\n",
        "\n",
        "  if layer.name in contents_layer_names:\n",
        "    conent_outputs_gen.append(z)\n",
        "\n",
        "# define model\n",
        "model = tf.keras.Model(\n",
        "    inputs = model_gen.input,\n",
        "    outputs = style_outputs_gen + contents_outputs_gen\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 20s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-97fc4a1db9c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mstyle_outputs_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontents_layer_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mconent_outputs_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'contents_layer_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx3hGgpwbDw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}